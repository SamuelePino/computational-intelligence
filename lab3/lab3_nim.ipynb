{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: Policy Search\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The player **taking the last object wins**.\n",
    "\n",
    "* Task3.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task3.2: An agent using evolved rules\n",
    "* Task3.3: An agent using minmax\n",
    "* Task3.4: An agent using reinforcement learning\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab3` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from typing import Callable\n",
    "from copy import deepcopy\n",
    "from itertools import accumulate\n",
    "from operator import xor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n",
    "    \n",
    "    def state(self): \n",
    "        return\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies [HARDCODED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    *_, result = accumulate(state.rows, xor)\n",
    "    return result\n",
    "\n",
    "def cook_status(state: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k\n",
    "    ]\n",
    "    cooked[\"active_rows_number\"] = sum(o > 0 for o in state.rows)\n",
    "    cooked[\"shortest_row\"] = min((x for x in enumerate(state.rows) if x[1] > 0), key=lambda y: y[1])[0]\n",
    "    cooked[\"longest_row\"] = max((x for x in enumerate(state.rows)), key=lambda y: y[1])[0]\n",
    "    cooked[\"nim_sum\"] = nim_sum(state)\n",
    "\n",
    "    brute_force = list()\n",
    "    for m in cooked[\"possible_moves\"]:\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(m)\n",
    "        brute_force.append((m, nim_sum(tmp)))\n",
    "    cooked[\"brute_force\"] = brute_force\n",
    "\n",
    "    return cooked\n",
    "\n",
    "def get_state(state: Nim):\n",
    "    pass \n",
    "\n",
    "def possible_moves(state: Nim):\n",
    "    try:\n",
    "        data = cook_status(state=state)[\"possible_moves\"]\n",
    "        state_dict = {} #   Row: -> [nobj_1, nobj_2, ...]\n",
    "\n",
    "        for move in data:\n",
    "            row = move[0]\n",
    "            nobj = move[1]\n",
    "            if row in state_dict:\n",
    "                state_dict[row].append(nobj)\n",
    "            else: \n",
    "                state_dict[row] = [nobj]\n",
    "        return state_dict\n",
    "\n",
    "    except:\n",
    "        print(\"Game Ended\")\n",
    "        return [-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variable for semplicity\n",
    "turn = 0\n",
    "\n",
    "def fast(state: Nim) -> Nimply:\n",
    "    \"\"\"\n",
    "    Take the max elements if its turn is its even one otherwise it will take one random element\n",
    "    \"\"\"\n",
    "\n",
    "    data = cook_status(state)\n",
    "\n",
    "    if (turn // 2)%2 == 0:\n",
    "\n",
    "        #Take max from the row with most elements\n",
    "        row = data[\"longest_row\"]\n",
    "\n",
    "        if state.k is None:\n",
    "            num_objects = state.rows[row]\n",
    "        else:\n",
    "            if state.rows[row] > state.k:\n",
    "                num_objects = state.k\n",
    "            else: \n",
    "                num_objects = state.rows[row]\n",
    "    else:\n",
    "        #Take 1 single element from a random row\n",
    "        row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "        num_objects = 1\n",
    "        \n",
    "    return Nimply(row, num_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_startegy(state: Nim) -> Nimply:\n",
    "    data = cook_status(state)\n",
    "    return next((bf for bf in data[\"brute_force\"] if bf[1] == 0), random.choice(data[\"brute_force\"]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MATCHES = 10\n",
    "NIM_SIZE = 10\n",
    "\n",
    "def evaluate(strategy: Callable) -> float:\n",
    "    opponent = (strategy, fast)\n",
    "    won = 0\n",
    "\n",
    "    for m in range(NUM_MATCHES):\n",
    "        nim = Nim(NIM_SIZE)\n",
    "        player = 0\n",
    "        while nim:\n",
    "            ply = opponent[player](nim)\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 1:\n",
    "            won += 1\n",
    "    return won / NUM_MATCHES\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Agent def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Agent(object):\n",
    "    def __init__(self, dim_nim, alpha=0.15, random_factor=0.2):  # 80% explore, 20% exploit\n",
    "\n",
    "        self.state_history = [(Nim(dim_nim).rows, (0,0), 0)]  # state, action, reward\n",
    "        self.alpha = alpha\n",
    "        self.random_factor = random_factor\n",
    "        self.G = {}\n",
    "        init_state = Nim(dim_nim)\n",
    "        self.init_reward(init_state)\n",
    "\n",
    "    def init_reward(self, init_state):\n",
    "        \"\"\"for i, row in enumerate(states):\n",
    "            for j, col in enumerate(row):\n",
    "                self.G[(j, i)] = np.random.uniform(low=1.0, high=0.1)\n",
    "        \"\"\"\n",
    "        \n",
    "        allowed_moves = cook_status(init_state)[\"possible_moves\"]\n",
    "        action_and_val = {}\n",
    "\n",
    "        for move in allowed_moves:\n",
    "            g = np.random.uniform(low=7.0, high=0.5)\n",
    "            action_and_val[move] = g\n",
    "        \n",
    "        GAME_ENDED = tuple( 0 for i in range(len(init_state.rows)))\n",
    "        self.G[init_state.rows] = action_and_val\n",
    "        self.G[GAME_ENDED] = -1\n",
    "                \n",
    "        \n",
    "    def choose_action(self, state, allowedMoves) -> Nimply:\n",
    "        maxG = -10e15\n",
    "        next_move = None\n",
    "\n",
    "        if state.rows not in self.G:\n",
    "        \n",
    "            #print(\"Never seen this before... Random?\")\n",
    "            self.init_reward(state)\n",
    "            next_move = random.choice(allowedMoves)\n",
    "\n",
    "        else:\n",
    "            #print(\"Already seen,\")\n",
    "            if random.random() < self.random_factor:\n",
    "                # if random number below random factor, choose random action\n",
    "                #print(\"lets try random:\")\n",
    "                next_move = random.choice(allowedMoves)\n",
    "            else:\n",
    "                # if exploiting, gather all possible actions and choose one with the highest G (reward)\n",
    "                if state.rows in self.G:\n",
    "                    #print(\"I KNOW WHAT TO DO!:\")\n",
    "                    actions_and_val = self.G[state.rows]\n",
    "\n",
    "                    for action in actions_and_val:\n",
    "                        g = actions_and_val[action]\n",
    "                        if g >= maxG:\n",
    "                            next_move = action\n",
    "                            maxG = g\n",
    "          \n",
    "        #print(next_move)\n",
    "        return Nimply(next_move[0], next_move[1])\n",
    "\n",
    "\n",
    "    def update_state_history(self, state, action_taken, reward):\n",
    "        self.state_history.append((state.rows, action_taken, reward))\n",
    "\n",
    "    def learn(self):\n",
    "        target = 0\n",
    "\n",
    "        for a in reversed(self.state_history):\n",
    "            #print(a)\n",
    "            try:\n",
    "                st, act, rew = a\n",
    "                # print(\"s\",st, \"a\", act, \"r\", rew)\n",
    "                possible_moves_values = self.G[st]\n",
    "\n",
    "                if possible_moves_values == -1:\n",
    "                    continue\n",
    "\n",
    "                g = possible_moves_values[act]\n",
    "                g = g + self.alpha * (target -g) #   + o - ?\n",
    "                target += rew\n",
    "            except:\n",
    "                #print(\"Something happened...(?) Nevermind\")\n",
    "                break\n",
    "                \n",
    "        self.state_history = []\n",
    "\n",
    "        self.random_factor -= 10e-5  # decrease random factor each episode of play\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversimplified match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logging.debug(f\"status: Initial board  -> {nim}\")\\nplayer = 0\\n\\nturn = 0\\nwhile nim:\\n    ply = strategy[player](nim)\\n    nim.nimming(ply)\\n    #logging.debug(f\"[{turn}] - status: After player {player} -> {nim}\")\\n    player = 1 - player\\n    turn += 1\\nwinner = 1 - player\\nlogging.info(f\"status: Player {winner} won!\")\\n'"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "strategy = (fast, optimal_startegy)\n",
    "nim = Nim(11)\n",
    "\n",
    "#print(possible_moves(nim))\n",
    "start_setup = possible_moves(nim)\n",
    "\n",
    "robot = Agent(nim)\n",
    "\n",
    "\"\"\"logging.debug(f\"status: Initial board  -> {nim}\")\n",
    "player = 0\n",
    "\n",
    "turn = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim)\n",
    "    nim.nimming(ply)\n",
    "    #logging.debug(f\"[{turn}] - status: After player {player} -> {nim}\")\n",
    "    player = 1 - player\n",
    "    turn += 1\n",
    "winner = 1 - player\n",
    "logging.info(f\"status: Player {winner} won!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_NIM = 11\n",
    "nim = Nim(DIM_NIM)\n",
    "winning_records = {0:0, 1:0}\n",
    "\n",
    "robot = Agent(DIM_NIM, alpha=0.1)\n",
    "robot_number = 0\n",
    "\n",
    "EPISODES = 10000\n",
    "for i in range(EPISODES):\n",
    "    player = random.choice([0,1])\n",
    "    while nim:\n",
    "       \n",
    "        if player == 0:\n",
    "            state = nim # get the current state\n",
    "            # choose an action (explore or exploit)\n",
    "            allowed_moves = cook_status(nim)[\"possible_moves\"]\n",
    "            action = robot.choose_action(state, allowed_moves)\n",
    "            # get the new state and reward\n",
    "            reward = 0  \n",
    "            # update the robot memory with state and reward\n",
    "            robot.update_state_history(state, action, reward)\n",
    "            nim.nimming(ply=action) # update the nim according to the action\n",
    "\n",
    "        else:\n",
    "            ply = fast(nim)\n",
    "            nim.nimming(ply)\n",
    "        player = 1 - player\n",
    "        \n",
    "    winner = 1 - player\n",
    "\n",
    "    if winner == robot_number:\n",
    "        reward = 1\n",
    "    else:\n",
    "        reward = -1\n",
    "\n",
    "    robot.update_state_history(state, action, reward)\n",
    "    robot.learn()  # robot should learn after every episode\n",
    "    nim = Nim(11) # reinitialize the Nim\n",
    "    winning_records[winner] += 1\n",
    "    #print(f\" [{i}] -> Winner is: \", winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 9524, 1: 476}\n"
     ]
    }
   ],
   "source": [
    "print(winning_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(agent: Agent, eps, nim: Nim, opp_strategy):\n",
    "    wr = {0:0, 1:0}\n",
    "    EPISODES = eps\n",
    "    for i in range(EPISODES):\n",
    "        player = random.choice([0,1])\n",
    "        while nim:\n",
    "        \n",
    "            if player == 0:\n",
    "                state = nim # get the current state\n",
    "                # choose an action (explore or exploit)\n",
    "                allowed_moves = cook_status(nim)[\"possible_moves\"]\n",
    "                action = agent.choose_action(state, allowed_moves)\n",
    "                nim.nimming(ply=action) # update the nim according to the action\n",
    "\n",
    "            else:\n",
    "                ply = optimal_startegy(nim)\n",
    "                nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "            \n",
    "        winner = 1 - player\n",
    "        nim = Nim(11) # reinitialize the Nim\n",
    "        wr[winner] += 1\n",
    "    return wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 100}\n"
     ]
    }
   ],
   "source": [
    "nim= Nim(11)\n",
    "wr = play(agent=robot, eps=100, nim=nim, opp_strategy=fast)\n",
    "print(wr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "12bacb19619b0d7f9afdf185f611b604bd918747e38ed48a19e12a1e72143883"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
